model:
  hidden_dims: [256, 128, 64]
  dropout: 0.2
  activation: "relu"
  batch_size: 1024
  lr: 0.001
  weight_decay: 0.0
  max_epochs: 50
  patience: 5


