stack:
  alpha: 0.5
  hidden_dims: [256, 128]
  dropout: 0.1
  activation: "relu"
  batch_size: 2048
  lr: 0.001
  weight_decay: 0.0
  max_epochs: 30
  patience: 5


